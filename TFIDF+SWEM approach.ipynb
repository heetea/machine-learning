{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nI will add new information to TFIDF+NN model(https://www.kaggle.com/ryches/tfidf-benchmark ).<br>\nTFIDF can create features based on actual vocabulary, but it can't handle well when there is another word of close meaning.<br>\nTherefore, I thought that adding SWEM(https://arxiv.org/abs/1805.09843) using learned word2vec as a feature value would increase the score."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gensim\nfrom nltk.corpus import brown\nimport random\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport gc\nfrom keras.callbacks.callbacks import EarlyStopping\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.callbacks.callbacks import EarlyStopping\nfrom scipy.stats import spearmanr\nfrom nltk.corpus import wordnet as wn\nimport tqdm\nfrom sklearn.model_selection import StratifiedKFold\n","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, Flatten, Dense","execution_count":146,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/google-quest-challenge/train.csv\")\ntest = pd.read_csv(\"../input/google-quest-challenge/test.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"(6079, 41)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train.columns)","execution_count":122,"outputs":[{"output_type":"execute_result","execution_count":122,"data":{"text/plain":"41"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(target_cols)","execution_count":123,"outputs":[{"output_type":"execute_result","execution_count":123,"data":{"text/plain":"30"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# fearure engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_prepro(s):\n    return [w for w in s.replace(\"\\n\",\" \").replace(\",\",\" , \").replace(\"(\",\" ( \").replace(\")\",\" ) \").\n            replace(\".\",\" . \").replace(\"?\",\" ? \").replace(\":\",\" : \").replace(\"n't\",\" not\").\n            replace(\"'ve\",\" have\").replace(\"'re\",\" are\").replace(\"'s\",\" is\").split(\" \") if w != \"\"]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_prepro_tfidf(s):\n    return \" \".join([w for w in s.lower().replace(\"\\n\",\" \").replace(\",\",\" , \").replace(\"(\",\" ( \").replace(\")\",\" ) \").\n            replace(\".\",\" . \").replace(\"?\",\" ? \").replace(\":\",\" : \").replace(\"n't\",\" not\").\n            replace(\"'ve\",\" have\").replace(\"'re\",\" are\").replace(\"'s\",\" is\").split(\" \") if w != \"\"])","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is basic preprocessing. This time, symbols and words are attached, so they are separated here."},{"metadata":{"trusted":true},"cell_type":"code","source":"qt_max = max([len(simple_prepro(l)) for l in list(train[\"question_title\"].values)])\nqb_max = max([len(simple_prepro(l))  for l in list(train[\"question_body\"].values)])\nan_max = max([len(simple_prepro(l))  for l in list(train[\"answer\"].values)])\nprint(\"max lenght of question_title is\",qt_max)\nprint(\"max lenght of question_body is\",qb_max)\nprint(\"max lenght of question_answer is\",an_max)","execution_count":75,"outputs":[{"output_type":"stream","text":"max lenght of question_title is 9.991939463727586\nmax lenght of question_body is 161.18703734166803\nmax lenght of question_answer is 163.19608488238197\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"qt_max = np.mean([len(simple_prepro(l)) for l in list(train[\"question_title\"].values)])\nqb_max = np.mean([len(simple_prepro(l))  for l in list(train[\"question_body\"].values)])\nan_max = np.mean([len(simple_prepro(l))  for l in list(train[\"answer\"].values)])\nprint(\"mean lenght of question_title is\",qt_max)\nprint(\"mean lenght of question_body is\",qb_max)\nprint(\"mean lenght of question_answer is\",an_max)","execution_count":77,"outputs":[{"output_type":"stream","text":"mean lenght of question_title is 9.991939463727586\nmean lenght of question_body is 161.18703734166803\nmean lenght of question_answer is 163.19608488238197\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_word = 35000\nmax_len = 1024\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=max_word)","execution_count":149,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [\"question_title\", \"question_body\", \"answer\"]:\n    tokenizer.fit_on_texts(train[i])    \nprint(len(tokenizer.word_index))","execution_count":150,"outputs":[{"output_type":"stream","text":"54531\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences_title = tokenizer.texts_to_sequences(train[\"question_title\"])\nsequences_body = tokenizer.texts_to_sequences(train[\"question_body\"])\nsequences_answer = tokenizer.texts_to_sequences(train[\"answer\"])\n\nfor i in [sequences_title,sequences_body,sequences_answer]:\n    print(len(i[0]))\n    print(i[0])","execution_count":151,"outputs":[{"output_type":"stream","text":"13\n[38, 71, 4, 3392, 46, 54, 1340, 5406, 281, 7, 3, 2131, 849]\n146\n[119, 877, 304, 16, 2131, 2987, 15, 1, 2148, 233, 6744, 849, 5154, 849, 4403, 15, 3, 1684, 849, 2537, 1340, 5406, 4, 41, 47, 2, 49, 876, 16, 12, 1, 656, 16, 1, 2124, 4, 117, 5, 9, 1302, 5, 1552, 6, 2837, 487, 5, 4704, 34, 263, 12, 1130, 29, 784, 2, 168, 5314, 233, 1993, 10684, 115, 22, 2191, 5, 6062, 4, 63, 2, 17, 227, 2, 3285, 887, 10684, 4, 839, 9, 13, 12, 10558, 6, 25582, 2837, 37, 17, 7, 597, 174, 33, 44, 1205, 26, 1518, 303, 5, 3, 2131, 849, 195, 6253, 15566, 2131, 165, 4, 71, 23, 193, 1172, 8, 538, 164, 1074, 849, 32, 1287, 5, 1, 2453, 1340, 5406, 1027, 13, 1292, 5852, 833, 38, 71, 4, 3392, 46, 54, 5406, 6482, 16, 3, 443, 849, 195, 25583, 985, 31, 214, 281, 7, 3, 2131, 849]\n151\n[4, 56, 394, 1340, 5406, 33, 715, 1, 23081, 38, 71, 4, 3392, 46, 54, 5406, 3, 136, 8697, 653, 7, 580, 2235, 9, 833, 30, 1, 108, 7, 1, 849, 2, 1, 1305, 25, 1327, 35, 580, 547, 2257, 2439, 16, 1, 492, 9, 606, 437, 3285, 2484, 250, 941, 2, 69, 2, 1170, 35, 2180, 5745, 1, 492, 1, 24, 437, 989, 136, 136, 3065, 691, 4, 839, 9, 2322, 4646, 31, 214, 5, 1209, 2, 17, 433, 3065, 1, 7514, 495, 7197, 1871, 7, 185, 7907, 4, 1001, 1979, 226, 155, 75, 1, 11279, 163, 1, 5405, 37, 168, 17, 433, 1130, 6482, 15, 29, 6565, 3, 474, 1340, 3778, 441, 8, 3, 5405, 7, 75, 3, 903, 3928, 8, 726, 7, 1, 849, 15, 29, 2322, 2420, 161, 324, 304, 31, 60, 3499, 8, 726, 7, 1, 849, 2, 75, 3, 3813, 8, 726, 7, 1, 849]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_pad = pad_sequences(sequences_title, maxlen=max_len)\nbody_pad =  pad_sequences(sequences_body, maxlen=max_len)\nanswer_pad =  pad_sequences(sequences_answer, maxlen=max_len)","execution_count":152,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"category\"].value_counts()","execution_count":153,"outputs":[{"output_type":"execute_result","execution_count":153,"data":{"text/plain":"TECHNOLOGY       2441\nSTACKOVERFLOW    1253\nCULTURE           963\nSCIENCE           713\nLIFE_ARTS         709\nName: category, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cate.shape","execution_count":154,"outputs":[{"output_type":"execute_result","execution_count":154,"data":{"text/plain":"(6079, 5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"type2int = {type:i for i,type in enumerate(list(set(train[\"category\"])))}\ncate = np.identity(5)[np.array(train[\"category\"].apply(lambda x:type2int[x]))].astype(np.float64)\ncate_test = np.identity(5)[np.array(test[\"category\"].apply(lambda x:type2int[x]))].astype(np.float64)","execution_count":155,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cate","execution_count":156,"outputs":[{"output_type":"execute_result","execution_count":156,"data":{"text/plain":"array([[1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [1., 0., 0., 0., 0.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"catego = np.zeros(title_pad.shape)\ncatego[:cate.shape[0],:cate.shape[1]] = cate","execution_count":157,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.array([title_pad, body_pad, answer_pad,catego])","execution_count":158,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.shape","execution_count":159,"outputs":[{"output_type":"execute_result","execution_count":159,"data":{"text/plain":"(4, 6079, 1024)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import LSTM, Dropout, Input, Conv1D\nfrom keras import backend\n","execution_count":196,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()","execution_count":197,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_word,4, input_length=max_len))\nmodel.add(LSTM(512))\nmodel.add(Dense(128, activation='relu')) # output = 1\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","execution_count":192,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model(length, vocab_size):\n\tinputs1 = Input(shape=(length,))\n\tembedding1 = Embedding(vocab_size, 100)(inputs1)\n\tconv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n\tdrop1 = Dropout(0.5)(conv1)\n\tpool1 = MaxPooling1D(pool_size=2)(drop1)\n\tflat1 = Flatten()(pool1)\n\t# channel 2\n\tinputs2 = Input(shape=(length,))\n\tembedding2 = Embedding(vocab_size, 100)(inputs2)\n\tconv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n\tdrop2 = Dropout(0.5)(conv2)\n\tpool2 = MaxPooling1D(pool_size=2)(drop2)\n\tflat2 = Flatten()(pool2)\n\t# channel 3\n\tinputs3 = Input(shape=(length,))\n\tembedding3 = Embedding(vocab_size, 100)(inputs3)\n\tconv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n\tdrop3 = Dropout(0.5)(conv3)\n\tpool3 = MaxPooling1D(pool_size=2)(drop3)\n\tflat3 = Flatten()(pool3)\n\t# merge\n\tmerged = concatenate([flat1, flat2, flat3])\n\t# interpretation\n\tdense1 = Dense(10, activation='relu')(merged)\n\toutputs = Dense(1, activation='sigmoid')(dense1)\n\tmodel = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n\t# compile\n\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\t# summarize\n\tprint(model.summary())\n\tplot_model(model, show_shapes=True, to_file='multichannel.png')\n\treturn model","execution_count":198,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = define_model(1024, len(tokenizer.word_index))","execution_count":199,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Conv1D' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-199-747c7cdff9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-198-ddbf83ae6487>\u001b[0m in \u001b[0;36mdefine_model\u001b[0;34m(length, vocab_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0minputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0membedding1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdrop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Conv1D' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":193,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 1024, 4)           140000    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 512)               1058816   \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n=================================================================\nTotal params: 1,272,736\nTrainable params: 1,272,736\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n\nhist = model.fit(train_x, train_y, epochs = 300, validation_split=0.2, callbacks = [es])","execution_count":181,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (4, 6079, 1024)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-181-0c3d856e54d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (4, 6079, 1024)"]}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"num_folds = 10\nfold_scores = []\nkf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\ntest_preds = np.zeros((len(test_features), len(target_cols)))\nvalid_preds = np.zeros((train_features.shape[0],30))\nfor train_index, val_index in kf.split(train_features):\n    gc.collect()\n    train_X = train_features[train_index, :]\n    train_y = train[target_cols].iloc[train_index]\n    \n    val_X = train_features[val_index, :]\n    val_y = train[target_cols].iloc[val_index]\n    \n    model = Sequential()\n    model.add(LSTM(1024, input_shape=(train_features.shape[1],), activation='relu'))\n    model.add(Dense(512, activation='relu')) # output = 1\n    model.add(Dense(len(target_cols), activation='sigmoid')) \n    \n    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy')\n    \n    model.fit(train_X, train_y, epochs = 300, validation_data=(val_X, val_y), callbacks = [es])\n    preds = model.predict(val_X)\n    valid_preds[val_index] = preds\n    overall_score = 0\n    for col_index, col in enumerate(target_cols):\n        overall_score += spearmanr(preds[:, col_index], val_y[col].values).correlation/len(target_cols)\n        print(col, spearmanr(preds[:, col_index], val_y[col].values).correlation)\n    fold_scores.append(overall_score)\n    print(overall_score)\n    test_preds += model.predict(test_features)/num_folds\nprint(fold_scores)","execution_count":31,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (5471, 503)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d1bf00485484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                   loss='binary_crossentropy')\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalid_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (5471, 503)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = 0\nfor col_index, col in enumerate(target_cols):\n    valid += spearmanr(valid_preds[:, col_index], train[col].values).correlation/30\nprint(\"valid score is \",valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\nfor col_index, col in enumerate(target_cols):\n    sub[col] = test_preds[:, col_index]\nsub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The contribution of the score was not great, but if you use bert etc. instead of brown, I think the score will go up more."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}